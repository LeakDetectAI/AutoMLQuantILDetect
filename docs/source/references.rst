ðŸ“šðŸ”–Bibliography
===============

List of references for the implemented learning algorithms, AutoML tools and baseline mutual information estimators


ðŸ“Š Learning Algorithms
======================
- `Multi-Layer Perceptron (MLP) <https://www.researchgate.net/publication/35657389_Beyond_regression_new_tools_for_prediction_and_analysis_in_the_behavioral_sciences>`_: Werbos (1974)
- `Consistency MLP <https://dl.acm.org/doi/10.1016/S0893-6080(09)80011-7>`_: Mielniczuk et al. (1993)
- `Random Forest (RF) <https://doi.org/10.1023/A:1010933404324>`_: Breiman (2001)
- `Consistency RF <https://dl.acm.org/doi/10.5555/1390681.1442799>`_: Biau et al. (2023)
- `Extra Trees (ET) <https://doi.org/10.1007/s10994-006-6226-1>`_: Geurts et al. (2006)
- `XGBoost (XGB) <https://doi.org/10.1145/2939672.2939785>`_: Chen and Guestrin (2016)
- `CatBoost (CB) <http://arxiv.org/abs/1810.11363>`_: Dorogush et al. (2018)
- `Classifier Calibration <https://dl.acm.org/doi/10.1007/s10994-023-06336-7>`_: Filho et al. (2023)


ðŸ¤– AutoML Tools
===============
- `TabPFN <https://arxiv.org/abs/2207.01848>`_: Hollmann et al. (2023)
- `AutoGluon <https://arxiv.org/abs/2003.06505>`_: Erickson et al. (2022)


ðŸš€ Baseline MI Estimators
=========================
- `Mutual Information Neural Estimation (MINE) <https://proceedings.mlr.press/v80/belghazi18a/belghazi18a.pdf>`_: Belghazi et al. (2018)
- `PC-softmax <https://arxiv.org/abs/1911.10688>`_: Qin et al. (2020)
